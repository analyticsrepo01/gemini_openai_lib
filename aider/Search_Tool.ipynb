{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3064778-460c-43e0-8d2e-0de7f4eddfc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### All Credits to Renzo Garcia for creating this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b42354b-e483-4183-8e97-76fcd3fbc1bb",
   "metadata": {},
   "source": [
    "# Vertex AI Search Agent Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f2875-0470-4d35-aac0-5ebb9fc64e75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-requisite Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a338e0f-ad4a-4b2f-8491-735d9801e4a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Enable APIs and service account permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bffef7-2a63-4151-b1b3-c9c1df3a020d",
   "metadata": {},
   "source": [
    "Enable the Vertex AI Search API:\n",
    "```\n",
    "gcloud services enable discoveryengine.googleapis.com\n",
    "```\n",
    "Enable the Enterprise Knowledge Graph API:\n",
    "```\n",
    "gcloud services enable enterpriseknowledgegraph.googleapis.com\n",
    "```\n",
    "Enable Cloud Run:\n",
    "```\n",
    "gcloud services enable run.googleapis.com\n",
    "```\n",
    "Give the Cloud Run service account required permissions:\n",
    "```\n",
    "gcloud projects add-iam-policy-binding [PROJECT_ID or PROJECT_NUMBER] --member='serviceAccount:[PROJECT_NUMBER]-compute@developer.gserviceaccount.com' --role='roles/discoveryengine.viewer'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6342ea-504e-447d-8076-dd4893c45be2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install Dependencies and set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3004dd-7e6d-44db-ba61-2f2f04b29a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install -q google-cloud-discoveryengine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86d1ff7-ba87-4d41-9ec8-b912e75714c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "import re\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import discoveryengine\n",
    "\n",
    "# Cloud project id.\n",
    "PROJECT_IDS = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_IDS[0]\n",
    "LOCATION = \"global\"\n",
    "\n",
    "UNIQUE_PREFIX = socket.gethostname()\n",
    "DATASTORE_NAME = re.sub('-', '_', UNIQUE_PREFIX)\n",
    "APP_NAME = re.sub('_', '-', UNIQUE_PREFIX)\n",
    "DATASTORE_ID = f\"{DATASTORE_NAME}_datastore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6dd71fa-9189-4618-b0a5-144a764634f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using this GCS Bucket: gs:// avatar-bucket-notebook\n",
      "Updated property [core/project].\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.storage.buckets.create) \"gcloud storage buckets create\" only accepts bucket URLs.\n",
      "Example: \"gs://bucket\"\n",
      "Received: \"gs://\"\n"
     ]
    }
   ],
   "source": [
    "# The Cloud Storage bucket for storing documents.\n",
    "REGION = \"asia-southeast1\"\n",
    "BUCKET_NAME = 'avatar-bucket-notebook' #f\"{PROJECT_ID}-{UNIQUE_PREFIX}-{REGION}\"\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"  # @param {type:\"string\"}\n",
    "print(f\"Using this GCS Bucket: {BUCKET_URI}\")\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "! gcloud storage buckets create {BUCKET_URI} --project={PROJECT_ID} --location={REGION} --no-public-access-prevention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971c484-1983-4c05-8471-e174aeeb7555",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting up Agent Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca5f00a-b5ff-4bde-9288-e03dadc4bd86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating a Datastore\n",
    "\n",
    "Data store's ingest data for your search app, including scraping websites, bigquery, google drive etc. ([reference](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "337fd60b-6ab7-4244-8ecc-6d4ea6670434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data_store(\n",
    "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
    "):\n",
    "    # Create a client\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "    client = discoveryengine.DataStoreServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    data_store = discoveryengine.DataStore(\n",
    "        display_name=data_store_name,\n",
    "        industry_vertical=\"GENERIC\",\n",
    "        content_config=\"CONTENT_REQUIRED\",\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateDataStoreRequest(\n",
    "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
    "            project_id, location, \"default_collection\"\n",
    "        ),\n",
    "        data_store=data_store,\n",
    "        data_store_id=data_store_id,\n",
    "    )\n",
    "    operation = client.create_data_store(request=request)\n",
    "\n",
    "    # Make the request\n",
    "    # The try block is necessary to prevent execution from halting due to an error being thrown when the datastore takes a while to instantiate\n",
    "    try:\n",
    "        response = operation.result(timeout=90)\n",
    "    except:\n",
    "        print(\"long-running operation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5374232-4cae-4db2-a7e2-676f4e55e872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore if datastore already exists, if first time, delete existing engine or change name\n",
      "Error: 409 DataStore projects/255766800726/locations/global/collections/default_collection/dataStores/pytorch_1_12_kaggle_wbi_datastore already exists.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    create_data_store(PROJECT_ID, LOCATION, DATASTORE_NAME, DATASTORE_ID)\n",
    "except Exception as e:\n",
    "    print(\"Ignore if datastore already exists, if first time, delete existing engine or change name\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4215a-3765-4034-9566-efb3977dc4a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Documents (Cloud Storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3222bd7-9765-40ce-9bd5-0d25cc593152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_documents(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    gcs_uri: str,\n",
    "):\n",
    "    # Create a client\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "    client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the search engine branch.\n",
    "    # e.g. projects/{project}/locations/{location}/dataStores/{data_store_id}/branches/{branch}\n",
    "    parent = client.branch_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        branch=\"default_branch\",\n",
    "    )\n",
    "\n",
    "    source_documents = [f\"{gcs_uri}/*\"]\n",
    "\n",
    "    request = discoveryengine.ImportDocumentsRequest(\n",
    "        parent=parent,\n",
    "        gcs_source=discoveryengine.GcsSource(\n",
    "            input_uris=source_documents, data_schema=\"content\"\n",
    "        ),\n",
    "        # Options: `FULL`, `INCREMENTAL`\n",
    "        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.import_documents(request=request)\n",
    "\n",
    "    response = operation.result()\n",
    "\n",
    "    # Once the operation is complete,\n",
    "    # get information from operation metadata\n",
    "    metadata = discoveryengine.ImportDocumentsMetadata(operation.metadata)\n",
    "\n",
    "    # Handle the response\n",
    "    return operation.operation.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9d381-7d02-4e96-a6bb-122c302dc18a",
   "metadata": {},
   "source": [
    "### ### Upload all your documents to this BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6da24908-298e-4e08-bfab-8adf61a1c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2004Q3_earnings.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2004Q4_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2004_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2005Q1_earnings_google.pdf...\n",
      "/ [4 files][  2.0 MiB/  2.0 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2005Q2_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2005Q3_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2005Q4_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2005_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2006Q3_google_earnings_slides.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2006Q4_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2006_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2007Q1_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2007Q2_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2007Q3_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2007Q4_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2007_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2008Q1_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2008Q2_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2008Q3_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2008Q4_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2008_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2009Q1_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2009Q2_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2009Q3_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2009Q4_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2009_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2010_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2011Q1_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2011Q2_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2011Q3_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2011Q4_earnings_google.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2011_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2012Q1_google_earnings.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2012Q2_google_earnings.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2012Q3_google_earnings.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2012Q4_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2012_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2013Q1_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2013Q2_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2013Q3_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2013Q4_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2013_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2014Q1_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2014Q2_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2014Q3_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2014Q4_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2014_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2015Q1_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2015Q2_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2015Q3_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2015Q4_google_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2015_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2016Q1_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2016Q2_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2016Q3_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2016Q4_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2016_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2017Q1_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2017Q2_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2017Q3_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2017Q4_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2017_google_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2018Q1_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2018Q2_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2018Q3_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2018Q4_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2018_alphabet_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2019Q1_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2019Q2_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2019Q3_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2019Q4_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2019_alphabet_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2020Q1_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2020Q2_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2020Q3_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2020Q4_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2020_alphabet_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2021Q1_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2021Q2_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2021Q3_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2021Q4_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2021_alphabet_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2022Q1_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2022Q2_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2022Q3_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2022Q4_alphabet_earnings_release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2022_alphabet_annual_report.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2023q1-alphabet-earnings-release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2023q2-alphabet-earnings-release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2023q3-alphabet-earnings-release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2023q4-alphabet-earnings-release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2024q1-alphabet-earnings-release-pdf.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2024q2-alphabet-earnings-release.pdf...\n",
      "Copying gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/goog023-alphabet-2023-annual-report-web-1.pdf...\n",
      "/ [94 files][ 89.1 MiB/ 89.1 MiB]   12.2 MiB/s                                  \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "\n",
      "Operation completed over 94 objects/89.1 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2e60f59-4495-469d-9eda-29d4fd5914a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUCKET_URI gs:// avatar-bucket-notebook\n"
     ]
    }
   ],
   "source": [
    "print('BUCKET_URI' , BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4cb1e10-f50d-4122-8698-5aa6f9227f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 404 Bucket \" avatar-bucket-notebook\" not found for operation OP_GET_BUCKET_METADATA\n"
     ]
    }
   ],
   "source": [
    "source_documents_gs_uri = (\n",
    "    BUCKET_URI #\"gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs\"\n",
    ")\n",
    "try:\n",
    "    import_documents(PROJECT_ID, LOCATION, DATASTORE_ID, source_documents_gs_uri)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff8ffd5-be3a-4d4d-b84d-6d75cf2fdf32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Creating a Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "055c6214-d872-4fc0-897d-f5a4fe7c62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_engine(\n",
    "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
    "):\n",
    "    # Create a client\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "    client = discoveryengine.EngineServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    config = discoveryengine.Engine.SearchEngineConfig(\n",
    "        search_tier=\"SEARCH_TIER_ENTERPRISE\", search_add_ons=[\"SEARCH_ADD_ON_LLM\"]\n",
    "    )\n",
    "\n",
    "    engine = discoveryengine.Engine(\n",
    "        display_name=data_store_name,\n",
    "        solution_type=\"SOLUTION_TYPE_SEARCH\",\n",
    "        industry_vertical=\"GENERIC\",\n",
    "        data_store_ids=[data_store_id],\n",
    "        search_engine_config=config,\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateEngineRequest(\n",
    "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
    "            project_id, location, \"default_collection\"\n",
    "        ),\n",
    "        engine=engine,\n",
    "        engine_id=engine.display_name,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.create_engine(request=request)\n",
    "    response = operation.result(timeout=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67b810ab-be88-49fa-9360-dc379d407918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore if engine already exists, if first time, delete existing engine or change name\n",
      "Error: 409 Engine with name \"projects/255766800726/locations/global/collections/default_collection/engines/pytorch-1-12-kaggle-wbi\" already exists.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    create_engine(PROJECT_ID, LOCATION, APP_NAME, DATASTORE_ID)\n",
    "except Exception as e:\n",
    "    print(\"Ignore if engine already exists, if first time, delete existing engine or change name\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c159388-f05c-47f0-922a-64c7eacec880",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Query Datastore (Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11241b8d-7784-48ce-8292-faab91cc7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    search_query: str,\n",
    ") -> list[discoveryengine.SearchResponse]:\n",
    "    #  For more information, refer to:\n",
    "    # https://cloud.google.com/generative-ai-app-builder/docs/locations#specify_a_multi-region_for_your_data_store\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if LOCATION != \"global\"\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # Create a client\n",
    "    client = discoveryengine.SearchServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the search engine serving config\n",
    "    # e.g. projects/{project_id}/locations/{location}/dataStores/{data_store_id}/servingConfigs/{serving_config_id}\n",
    "    serving_config = client.serving_config_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        serving_config=\"default_config\",\n",
    "    )\n",
    "\n",
    "    # Optional: Configuration options for search\n",
    "    # Refer to the `ContentSearchSpec` reference for all supported fields:\n",
    "    # https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.types.SearchRequest.ContentSearchSpec\n",
    "    content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(\n",
    "        # For information about snippets, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/snippets\n",
    "        snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(\n",
    "            return_snippet=True\n",
    "        ),\n",
    "        # For information about search summaries, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/get-search-summaries\n",
    "        summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(\n",
    "            summary_result_count=5,\n",
    "            include_citations=True,\n",
    "            ignore_adversarial_query=True,\n",
    "            ignore_non_summary_seeking_query=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Refer to the `SearchRequest` reference for all supported fields:\n",
    "    # https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.types.SearchRequest\n",
    "    request = discoveryengine.SearchRequest(\n",
    "        serving_config=serving_config,\n",
    "        query=search_query,\n",
    "        page_size=10,\n",
    "        content_search_spec=content_search_spec,\n",
    "        query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(\n",
    "            condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,\n",
    "        ),\n",
    "        spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(\n",
    "            mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    response = client.search(request)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba069bd6-8f26-4a3b-8cbf-a86941f5bd65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the CEO of Google?\"\n",
    "\n",
    "print(search_sample(PROJECT_ID, LOCATION, DATASTORE_ID, query).summary.summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f9b49-a2c3-4435-92d4-f2b768f5d38b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Query Datastore (Multi-turn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abb2672c-4ae4-4338-b351-3241a4bedf95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import discoveryengine_v1 as discoveryengine\n",
    "\n",
    "def multi_turn_search_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    search_queries: List[str],\n",
    ") -> List[discoveryengine.ConverseConversationResponse]:\n",
    "    #  For more information, refer to:\n",
    "    # https://cloud.google.com/generative-ai-app-builder/docs/locations#specify_a_multi-region_for_your_data_store\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # Create a client\n",
    "    client = discoveryengine.ConversationalSearchServiceClient(\n",
    "        client_options=client_options\n",
    "    )\n",
    "\n",
    "    # Initialize Multi-Turn Session\n",
    "    conversation = client.create_conversation(\n",
    "        # The full resource name of the data store\n",
    "        # e.g. projects/{project_id}/locations/{location}/dataStores/{data_store_id}\n",
    "        parent=client.data_store_path(\n",
    "            project=project_id, location=location, data_store=data_store_id\n",
    "        ),\n",
    "        conversation=discoveryengine.Conversation(),\n",
    "    )\n",
    "\n",
    "\n",
    "    for search_query in search_queries:\n",
    "        # Add new message to session\n",
    "        request = discoveryengine.ConverseConversationRequest(\n",
    "            name=conversation.name,\n",
    "            query=discoveryengine.TextInput(input=search_query),\n",
    "            serving_config=client.serving_config_path(\n",
    "                project=project_id,\n",
    "                location=location,\n",
    "                data_store=data_store_id,\n",
    "                serving_config=\"default_config\",\n",
    "            ),\n",
    "            # Options for the returned summary\n",
    "            summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(\n",
    "                # Number of results to include in summary\n",
    "                summary_result_count=3,\n",
    "                include_citations=True,\n",
    "            ),\n",
    "        )\n",
    "        response = client.converse_conversation(request)\n",
    "\n",
    "        print(f\"Reply: {response.reply.summary.summary_text}\\n\")\n",
    "\n",
    "        for i, result in enumerate(response.search_results, 1):\n",
    "            result_data = result.document.derived_struct_data\n",
    "            print(f\"[{i}]\")\n",
    "            print(f\"Link: {result_data['link']}\")\n",
    "            print(f\"First Snippet: {result_data['snippets'][0]['snippet']}\")\n",
    "            print(\n",
    "                \"First Extractive Answer: \\n\"\n",
    "                f\"\\tPage: {result_data['extractive_answers'][0]['pageNumber']}\\n\"\n",
    "                f\"\\tContent: {result_data['extractive_answers'][0]['content']}\\n\\n\"\n",
    "            )\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cb46da6-7c8e-4c8d-a387-42f0fb11b109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FailedPrecondition",
     "evalue": "400 This feature is only available when Large Language Model add-on is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1175\u001b[0m (\n\u001b[1;32m   1176\u001b[0m     state,\n\u001b[1;32m   1177\u001b[0m     call,\n\u001b[1;32m   1178\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1180\u001b[0m )\n\u001b[0;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"This feature is only available when Large Language Model add-on is enabled.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.152.95:443 {created_time:\"2024-10-29T17:09:09.567574422+00:00\", grpc_status:9, grpc_message:\"This feature is only available when Large Language Model add-on is enabled.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho is the CEO of Google?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhere is their office located\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmulti_turn_search_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROJECT_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOCATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASTORE_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[27], line 26\u001b[0m, in \u001b[0;36mmulti_turn_search_sample\u001b[0;34m(project_id, location, data_store_id, search_queries)\u001b[0m\n\u001b[1;32m     21\u001b[0m client \u001b[38;5;241m=\u001b[39m discoveryengine\u001b[38;5;241m.\u001b[39mConversationalSearchServiceClient(\n\u001b[1;32m     22\u001b[0m     client_options\u001b[38;5;241m=\u001b[39mclient_options\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Initialize Multi-Turn Session\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m conversation \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_conversation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The full resource name of the data store\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# e.g. projects/{project_id}/locations/{location}/dataStores/{data_store_id}\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_store_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_store_id\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconversation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscoveryengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m search_query \u001b[38;5;129;01min\u001b[39;00m search_queries:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Add new message to session\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     request \u001b[38;5;241m=\u001b[39m discoveryengine\u001b[38;5;241m.\u001b[39mConverseConversationRequest(\n\u001b[1;32m     39\u001b[0m         name\u001b[38;5;241m=\u001b[39mconversation\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     40\u001b[0m         query\u001b[38;5;241m=\u001b[39mdiscoveryengine\u001b[38;5;241m.\u001b[39mTextInput(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39msearch_query),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m         ),\n\u001b[1;32m     53\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/discoveryengine_v1/services/conversational_search_service/client.py:1095\u001b[0m, in \u001b[0;36mConversationalSearchServiceClient.create_conversation\u001b[0;34m(self, request, parent, conversation, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1095\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m: 400 This feature is only available when Large Language Model add-on is enabled."
     ]
    }
   ],
   "source": [
    "query = [\n",
    "    \"Who is the CEO of Google?\", \n",
    "    \"Where is their office located\"\n",
    "]\n",
    "\n",
    "print(multi_turn_search_sample(PROJECT_ID, LOCATION, DATASTORE_ID, query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba6a92-2a28-4d6f-bf5a-503a8f8b2898",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Streamlit Search App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031624ee-f2d2-4565-9c3e-c9b11a31c53f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install dependencies for Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd66124-7b97-480e-a9c7-540db9b6d38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install -q streamlit\n",
    "!pip3 install -q python-dotenv\n",
    "!pip3 install -q google-cloud-aiplatform\n",
    "!pip3 install -q google-generativeai\n",
    "\n",
    "! mkdir pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9cf94-0ca2-43ed-b527-6675548aa2a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create main Search page for app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ba1bc-ebe6-47c0-bcbd-bdcc82baafee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile Search.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import discoveryengine_v1 as discoveryengine\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Tool,\n",
    "    grounding,\n",
    ")\n",
    "import re\n",
    "\n",
    "def replace_bold_tags(text):\n",
    "  return re.sub(r\"<b>(.*?)</b>\", r\"**\\1**\", text)\n",
    "\n",
    "PROJECT_ID = sys.argv[1]\n",
    "LOCATION = \"global\"\n",
    "DATASTORE_ID = sys.argv[2]\n",
    "\n",
    "def search_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    search_query: str,\n",
    "    no_results: int ,\n",
    "    no_snippets: int,\n",
    "    no_extract: int,\n",
    "    no_extract_seg: int,\n",
    "    no_top_results: int\n",
    ") -> list[discoveryengine.SearchResponse]:\n",
    "\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if LOCATION != \"global\"\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    client = discoveryengine.SearchServiceClient(client_options=client_options)\n",
    "\n",
    "    serving_config = client.serving_config_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        serving_config=\"default_config\",\n",
    "    )\n",
    "    content_search_spec = {\n",
    "        'snippet_spec': {'return_snippet': True if no_snippets == 1 else False},\n",
    "        'extractive_content_spec': {\n",
    "            'max_extractive_answer_count': no_extract,\n",
    "            'max_extractive_segment_count': no_extract_seg,\n",
    "            'return_extractive_segment_score': True,\n",
    "        },\n",
    "        'summary_spec': {\n",
    "            'summary_result_count': no_top_results,\n",
    "            'include_citations': True,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    request = discoveryengine.SearchRequest(\n",
    "        serving_config=serving_config,\n",
    "        query=search_query,\n",
    "        page_size=no_results,\n",
    "        content_search_spec=content_search_spec,\n",
    "        query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(\n",
    "            condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,\n",
    "        ),\n",
    "        spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(\n",
    "            mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    response = client.search(request)\n",
    "    return response\n",
    "\n",
    "def llm_prompt(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    llm_model: str,\n",
    "    prompt: str,\n",
    "    temp,\n",
    "    top_k,\n",
    "    top_p\n",
    "):\n",
    "    vertexai.init(project=project_id, location=\"us-central1\")\n",
    "\n",
    "    model = GenerativeModel(llm_model)\n",
    "    tool = Tool.from_retrieval(grounding.Retrieval(grounding.VertexAISearch(datastore=data_store_id, project=project_id, location=\"global\")))\n",
    "\n",
    "    response = model.generate_content(\n",
    "        prompt,\n",
    "        tools=[tool],\n",
    "        generation_config=GenerationConfig(\n",
    "            temperature=temp,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return(response.text)\n",
    "\n",
    "def rerank(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    prompt: str,\n",
    "    top_n,\n",
    "    records\n",
    "):\n",
    "    reformatted_record = reformat_rerank(records)\n",
    "    client = discoveryengine.RankServiceClient()\n",
    "    \n",
    "    ranking_config = client.ranking_config_path(\n",
    "        project=project_id,\n",
    "        location=\"global\",\n",
    "        ranking_config=\"default_ranking_config\",\n",
    "    )\n",
    "    request = discoveryengine.RankRequest(\n",
    "        ranking_config=ranking_config,\n",
    "        model=\"semantic-ranker-512@latest\",\n",
    "        top_n=top_n,\n",
    "        query=prompt,\n",
    "        records=reformatted_record\n",
    "    )\n",
    "\n",
    "    response = client.rank(request=request)\n",
    "    return response\n",
    "\n",
    "def reformat_rerank(unformatted):\n",
    "    records = []\n",
    "    for result in unformatted:\n",
    "        for extract in result.document.derived_struct_data['extractive_answers']:\n",
    "            record = discoveryengine.RankingRecord(\n",
    "                id=f\"{extract['pageNumber']}_{result.id}\",\n",
    "                title=result.document.derived_struct_data['title'],\n",
    "                content=extract['content']\n",
    "            )\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def main():\n",
    "# --- App layout ---\n",
    "    st.set_page_config(page_title=\"Search\", layout='wide')\n",
    "    st.title('Search')  \n",
    "    \n",
    "    with st.sidebar:\n",
    "        st.title('Configurations')\n",
    "        llm_model = st.selectbox(\n",
    "            \"LLM Model\",\n",
    "            (\"Vertex AI Search(default)\", \"gemini-1.5-flash-001\", \"gemini-1.5-pro-001\"),\n",
    "        )\n",
    "        if llm_model is not \"Vertex AI Search(default)\":\n",
    "            st.divider()\n",
    "            temp = st.number_input(\"Temp\", 0.0, 1.0, 0.0)\n",
    "            top_k = st.number_input(\"Top K\", 0, 100, 40)\n",
    "            top_p = st.number_input(\"Top P\", 0.0, 1.0, 0.95)\n",
    "        st.divider()\n",
    "        re_rank = st.toggle(\"Re-Rank\")\n",
    "        if re_rank:\n",
    "            top_n = st.number_input(\"Top N\", 1, 10, 10)\n",
    "        no_results = st.slider(\"Results per Page\", 1, 10, 10)\n",
    "        no_snippets = st.slider(\"Snippets per Result\", 0, 1, 1)\n",
    "        no_extract = st.slider(\"Results per Page\", 0, 5, 3)\n",
    "        no_extract_seg = st.slider(\"Results per Page\", 1, 10, 3)\n",
    "        no_top_results = st.slider(\"Results per Page\", 1, 5, 5)\n",
    "        \n",
    "    search_prompt = st.text_input(\"Search Internal Documents\", value=\"what is the revenue for 2024?\")\n",
    "    if st.button(\"Generate\"):\n",
    "        search_response = search_sample(PROJECT_ID, LOCATION, DATASTORE_ID, search_prompt, no_results, no_snippets, no_extract, no_extract_seg, no_top_results)\n",
    "        st.subheader(\"AI Answer\")\n",
    "        \n",
    "        container = st.container(border=True)\n",
    "        if llm_model is \"Vertex AI Search(default)\":\n",
    "            container.markdown(replace_bold_tags(search_response.summary.summary_text))\n",
    "        else:\n",
    "            container.markdown(replace_bold_tags(llm_prompt(PROJECT_ID, LOCATION, DATASTORE_ID, llm_model, search_prompt, temp, top_k, top_p)))\n",
    "        \n",
    "        st.subheader(\"Results\")\n",
    "        if re_rank:\n",
    "            response = rerank(PROJECT_ID, LOCATION, search_prompt, top_n, search_response.results)\n",
    "            for result in response.records:\n",
    "                container = st.container(border=True)\n",
    "                container.subheader(result.title)\n",
    "                container.write(f\"Page {result.id.split('_')[0]}\")\n",
    "                container.write(f\"Score: {result.score}\")\n",
    "                container.markdown(replace_bold_tags(result.content))\n",
    "        else:\n",
    "            for result in search_response.results:\n",
    "                container = st.container(border=True)\n",
    "                container.subheader(result.document.derived_struct_data['title'])\n",
    "                for extract in result.document.derived_struct_data['extractive_answers']:\n",
    "                    container.write(f\"Page {extract['pageNumber']}\")\n",
    "                    container.markdown(replace_bold_tags(extract['content'])) \n",
    "\n",
    "# --- End of App layout ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b25380-0999-48c6-9d23-7558d262d5ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create Multi-turn page for app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f084847-0d7f-4f8d-90a2-5e0af9eb8d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile pages/Multi-Turn.py\n",
    "\n",
    "import streamlit as st\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import discoveryengine_v1 as discoveryengine\n",
    "from google.cloud import discoveryengine_v1alpha\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Tool,\n",
    "    grounding,\n",
    ")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "def replace_bold_tags(text):\n",
    "  return re.sub(r\"<b>(.*?)</b>\", r\"**\\1**\", text)\n",
    "\n",
    "def translate_role_for_streamlit(user_role):\n",
    "    if user_role == \"model\":\n",
    "        return \"assistant\"\n",
    "    else:\n",
    "        return user_role\n",
    "    \n",
    "def rerank(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    prompt: str,\n",
    "    top_n,\n",
    "    records\n",
    "):\n",
    "    reformatted_record = reformat_rerank(records)\n",
    "    client = discoveryengine.RankServiceClient()\n",
    "    \n",
    "    ranking_config = client.ranking_config_path(\n",
    "        project=project_id,\n",
    "        location=\"global\",\n",
    "        ranking_config=\"default_ranking_config\",\n",
    "    )\n",
    "    request = discoveryengine.RankRequest(\n",
    "        ranking_config=ranking_config,\n",
    "        model=\"semantic-ranker-512@latest\",\n",
    "        top_n=top_n,\n",
    "        query=prompt,\n",
    "        records=reformatted_record\n",
    "    )\n",
    "\n",
    "    response = client.rank(request=request)\n",
    "    return response\n",
    "\n",
    "def reformat_rerank(unformatted):\n",
    "    records = []\n",
    "    for result in unformatted:\n",
    "        for extract in result.document.derived_struct_data['extractive_answers']:\n",
    "            record = discoveryengine.RankingRecord(\n",
    "                id=f\"{extract['pageNumber']}_{result.id}\",\n",
    "                title=result.document.derived_struct_data['title'],\n",
    "                content=extract['content']\n",
    "            )\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = sys.argv[1]\n",
    "LOCATION = \"global\"\n",
    "DATASTORE_ID = sys.argv[2]\n",
    "\n",
    "# Create a client\n",
    "client_options = (\n",
    "    ClientOptions(api_endpoint=f\"{LOCATION}-discoveryengine.googleapis.com\")\n",
    "    if LOCATION != \"global\"\n",
    "    else None\n",
    ")\n",
    "client = discoveryengine.ConversationalSearchServiceClient(\n",
    "    client_options=client_options\n",
    ")\n",
    "\n",
    "# Initialize Multi-Turn Session\n",
    "conversation = client.create_conversation(\n",
    "    parent=client.data_store_path(\n",
    "        project=PROJECT_ID, location=LOCATION, data_store=DATASTORE_ID\n",
    "    ),\n",
    "    conversation=discoveryengine.Conversation(),\n",
    ")\n",
    "    \n",
    "st.set_page_config(page_title=\"Multi-Turn\", layout='wide')\n",
    "st.title('Multi-Turn')\n",
    "\n",
    "with st.sidebar:\n",
    "    st.title('Configurations')\n",
    "    llm_model = st.selectbox(\n",
    "        \"LLM Model\",\n",
    "        (\"Vertex AI Search(default)\", \"gemini-1.5-flash-001\", \"gemini-1.5-pro-001\"),\n",
    "    )\n",
    "    if llm_model is not \"Vertex AI Search(default)\":\n",
    "        st.divider()\n",
    "        temp = st.number_input(\"Temp\", 0.0, 1.0, 0.0)\n",
    "        top_k = st.number_input(\"Top K\", 0, 100, 40)\n",
    "        top_p = st.number_input(\"Top P\", 0.0, 1.0, 0.95)\n",
    "    st.divider()\n",
    "    re_rank = st.toggle(\"Re-Rank\")\n",
    "    if re_rank:\n",
    "        top_n = st.number_input(\"Top N\", 1, 10, 10)\n",
    "    no_results = st.slider(\"Results per Page\", 1, 10, 3)\n",
    "\n",
    "col1, col2 = st.columns(2, gap=\"medium\")    \n",
    "with col1:\n",
    "    st.subheader(\"Multi-turn Search\")\n",
    "    prompt = st.chat_input(\"Ask Follow-up Questions\")\n",
    "    \n",
    "with col2:\n",
    "    st.subheader(\"Reference Results\")\n",
    "    \n",
    "if prompt:\n",
    "    if llm_model is not \"Vertex AI Search(default)\":\n",
    "        vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "        model = GenerativeModel(llm_model)\n",
    "        tool = Tool.from_retrieval(\n",
    "            grounding.Retrieval(\n",
    "                grounding.VertexAISearch(\n",
    "                    datastore=DATASTORE_ID,\n",
    "                    project=PROJECT_ID,\n",
    "                    location=\"global\",\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        if \"chat_session\" not in st.session_state:\n",
    "            st.session_state.chat_session = model.start_chat(history=[])\n",
    "        gemini_response = st.session_state.chat_session.send_message(\n",
    "            prompt,\n",
    "            tools=[tool],\n",
    "            generation_config=GenerationConfig(\n",
    "                temperature=temp,\n",
    "                top_p=top_p,\n",
    "                top_k=top_k\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "    request = discoveryengine.ConverseConversationRequest(\n",
    "        query=discoveryengine.TextInput(input=prompt),\n",
    "        serving_config=client.serving_config_path(\n",
    "            project=PROJECT_ID,\n",
    "            location=LOCATION,\n",
    "            data_store=DATASTORE_ID,\n",
    "            serving_config=\"default_config\",\n",
    "        ),\n",
    "        name=conversation.name,\n",
    "        # Options for the returned summary\n",
    "        summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(\n",
    "            # Number of results to include in summary\n",
    "            summary_result_count=no_results,\n",
    "            include_citations=True,\n",
    "        ),\n",
    "    )\n",
    "    response = client.converse_conversation(request)\n",
    "\n",
    "    with col1:\n",
    "        # Display chat messages from history on app rerun\n",
    "        container = st.container(border=True, height=500)\n",
    "        \n",
    "        if llm_model is not \"Vertex AI Search(default)\":\n",
    "            for message in reversed(st.session_state.chat_session.history):\n",
    "                container.chat_message(translate_role_for_streamlit(message.role)).markdown(replace_bold_tags(message.parts[0].text))\n",
    "        else:\n",
    "            if \"messages\" not in st.session_state:\n",
    "                st.session_state.messages = []\n",
    "            st.session_state.messages.append({\"role\": \"user\", \"content\": replace_bold_tags(prompt)})\n",
    "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": replace_bold_tags(response.reply.summary.summary_text)})    \n",
    "            for message in reversed(st.session_state.messages):\n",
    "                container.chat_message(message[\"role\"]).markdown(replace_bold_tags(message[\"content\"]))\n",
    "\n",
    "    with col2:\n",
    "        container = st.container(border=True, height=550)\n",
    "        if re_rank:\n",
    "            response = rerank(PROJECT_ID, LOCATION, prompt, top_n, response.search_results)\n",
    "            for result in response.records:\n",
    "                subcontainer = container.container(border=True)\n",
    "                subcontainer.subheader(result.title)\n",
    "                subcontainer.write(f\"Page {result.id.split('_')[0]}\")\n",
    "                subcontainer.write(f\"Score: {result.score}\")\n",
    "                subcontainer.markdown(replace_bold_tags(result.content))\n",
    "        else:\n",
    "            for result in response.search_results:\n",
    "                subcontainer = container.container(border=True)\n",
    "                result_data = result.document.derived_struct_data\n",
    "                subcontainer.subheader(result_data['link'].split('/')[-1])\n",
    "                subcontainer.write(f\"    Page: {result_data['extractive_answers'][0]['pageNumber']}\")\n",
    "                subcontainer.markdown(f\"    {replace_bold_tags(result_data['extractive_answers'][0]['content'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd5791-9e4f-4f8b-ae24-f23baa352b32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create Datastore page for app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66b8e7-1f61-414d-84e8-0298671c033e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile pages/Datastore.py\n",
    "\n",
    "import streamlit as st\n",
    "from google.cloud import storage\n",
    "from google.cloud import discoveryengine\n",
    "from google.cloud import discoveryengine_v1beta\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_ID = sys.argv[1]\n",
    "LOCATION = \"global\"\n",
    "DATASTORE_ID = sys.argv[2]\n",
    "BUCKET_NAME = sys.argv[3]\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "# Create a client\n",
    "client_options = (\n",
    "    ClientOptions(api_endpoint=f\"{LOCATION}-discoveryengine.googleapis.com\")\n",
    "    if LOCATION != \"global\"\n",
    "    else None\n",
    ")\n",
    "doc_client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
    "\n",
    "def delete_blob(blob_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    blob = bucket.blob(blob_name)\n",
    "    try:\n",
    "        blob.delete()\n",
    "    except Exception as e:\n",
    "        st.write(e)\n",
    "\n",
    "def import_documents(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    source: str,\n",
    "):\n",
    "    parent = doc_client.branch_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        branch=\"default_branch\",\n",
    "    )\n",
    "\n",
    "    source_documents = source\n",
    "    request = discoveryengine.ImportDocumentsRequest(\n",
    "        parent=parent,\n",
    "        gcs_source=discoveryengine.GcsSource(\n",
    "            input_uris=source_documents, data_schema=\"content\"\n",
    "        ),\n",
    "        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL,\n",
    "    )\n",
    "    try:\n",
    "        operation = doc_client.import_documents(request=request)            \n",
    "    except Exception as e:\n",
    "        st.write(f\"Error: {e}\") \n",
    "\n",
    "    return discoveryengine.ImportDocumentsMetadata(operation.metadata)\n",
    "\n",
    "def purge_doc(\n",
    "    project,\n",
    "    location,\n",
    "    data_store,\n",
    "):\n",
    "    operation = doc_client.purge_documents(\n",
    "        request=discoveryengine.PurgeDocumentsRequest(\n",
    "            parent=doc_client.branch_path(\n",
    "                project=project,\n",
    "                location=location,\n",
    "                data_store=data_store,\n",
    "                branch=\"default_branch\",\n",
    "            ),\n",
    "            filter=\"*\",\n",
    "            force=True,\n",
    "        )\n",
    "    )\n",
    "    return operation.result()\n",
    "\n",
    "def purge_bucket():\n",
    "    blobs = storage_client.list_blobs(BUCKET_NAME)\n",
    "    for blob in blobs:\n",
    "        delete_blob(blob.name)\n",
    "\n",
    "def list_datastore(\n",
    "    project,\n",
    "    location,\n",
    "    data_store,\n",
    "):\n",
    "    parent = doc_client.branch_path(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        data_store=data_store,\n",
    "        branch=\"default_branch\",\n",
    "    )\n",
    "\n",
    "    return doc_client.list_documents(parent=parent)\n",
    "    \n",
    "st.set_page_config(page_title=\"Datastore\", layout='wide')\n",
    "st.title(\"Datastore\")\n",
    "\n",
    "uploaded_files = st.file_uploader(\"Choose a pdf or csv file\", type=['pdf','csv'], accept_multiple_files=True)\n",
    "\n",
    "action_container = st.container(border=True)\n",
    "col1, col2, col3 , col4= action_container.columns(4)\n",
    "\n",
    "metadata = str\n",
    "metadata_c = st.container(border=True)\n",
    "with col1:\n",
    "    if st.button(\"Import Documents\"):\n",
    "        if not uploaded_files:\n",
    "            metadata_c.write(\"No files to import\")\n",
    "        else:\n",
    "            source_documents = []\n",
    "            # Uploading files to gcs bucket\n",
    "            for uploaded_file in uploaded_files:\n",
    "                bytes_data = uploaded_file.read()\n",
    "                blob = bucket.blob(uploaded_file.name)\n",
    "                uploaded_file.seek(0) \n",
    "                blob.upload_from_file(uploaded_file)\n",
    "                source_documents.append('gs://' + BUCKET_NAME + '/' + uploaded_file.name)\n",
    "                # # Importing files from GCS bucket to datastore\n",
    "            with metadata_c:\n",
    "                with st.spinner(text=f\"Importing documents to {DATASTORE_ID}...\"):\n",
    "                    metadata = import_documents(PROJECT_ID, LOCATION, DATASTORE_ID, source_documents)\n",
    "            if metadata.total_count is 0:\n",
    "                metadata_c.write(\"Upload complete\")\n",
    "            else:\n",
    "                metadata_c.write(f\"{metadata.success_count} out of {metadata.total_count} successfully imported\")\n",
    "    \n",
    "with col2:\n",
    "    if st.button(\"Import Sample\"):\n",
    "        # Add a file uploader before this and feed the result back into this importer\n",
    "        source_documents_gs_uri = (\n",
    "            \"gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs\"\n",
    "        )\n",
    "        with metadata_c:\n",
    "            with st.spinner(text=f\"Importing documents to {DATASTORE_ID}...\"):\n",
    "                metadata = import_documents(PROJECT_ID, LOCATION, DATASTORE_ID, [source_documents_gs_uri + '/*'])\n",
    "        metadata_c.write(\"Upload complete\")\n",
    "            \n",
    "with col3:\n",
    "    if st.button(\"Purge Datastore\"):\n",
    "        purge_bucket()\n",
    "        response = purge_doc(PROJECT_ID, LOCATION, DATASTORE_ID)\n",
    "        with metadata_c:\n",
    "            metadata_c.write(f\"{response.purge_count} documents purged\")\n",
    "\n",
    "Document_list = st.container(border=True)\n",
    "doc_list = list_datastore(PROJECT_ID, LOCATION, DATASTORE_ID)\n",
    "Document_list.subheader('Documents in datastore')\n",
    "\n",
    "for doc in doc_list:\n",
    "    Document_list.markdown(f\"[{doc.content.uri.rsplit('/', 1)[1]}]({doc.content.uri.replace(r'gs://', r'https://storage.cloud.google.com/')})\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26b024-b111-454c-966a-ea343d6830a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run Streamlit app locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea3553-e6f5-404f-b5bf-a39ac78c54bc",
   "metadata": {},
   "source": [
    "To Access your app, go to the **External URL** link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19f925-aa88-4e8a-aa3d-ac99c4b14362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! python3 -m streamlit run Search.py {PROJECT_ID} {DATASTORE_ID} {BUCKET_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fbd5ca-28db-4d12-9149-f5974316dfea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy Streamlit Search App to Cloud Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e01da9-db91-4285-a7cf-ec380234e381",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Replace the following below:\n",
    "ai-sb-test with the project id and renzo_test_datastore with the data store id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9f2d0-3097-45da-988c-b2caf14c8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PROJECT_ID)\n",
    "print(DATASTORE_ID)\n",
    "print(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e5d4e-003b-4862-8a5a-c98a53a9ddb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM python:3.10\n",
    "\n",
    "EXPOSE 8080\n",
    "WORKDIR /app\n",
    "\n",
    "COPY . ./\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"streamlit\", \"run\", \"Search.py\", \"PROJECT_ID\", \"DATASTORE_ID\", \"BUCKET_NAME\", \"--server.port=8080\", \"--server.address=0.0.0.0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d0e72-fabd-455b-b854-1240efae0616",
   "metadata": {},
   "source": [
    "Generate requirements txt for later deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6bb48-d501-41a0-aef9-b8a9696ecff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "streamlit\n",
    "python-dotenv\n",
    "google-generativeai\n",
    "google-cloud-aiplatform\n",
    "google-cloud-discoveryengine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a0b29b-ca1f-4f81-ae35-fb9dcff13242",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy Cloud Run function (Uncomment to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7c493-f8b3-4255-b341-1edf3ef67604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCATION = 'asia-southeast1'\n",
    "! gcloud artifacts repositories create {APP_NAME}-repo --location={LOCATION} --repository-format=Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fda238-975e-403e-bded-fce9084a487d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gcloud auth configure-docker {LOCATION}-docker.pkg.dev -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768377e1-dd09-4736-8d8e-affc04f9b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud builds submit --tag {LOCATION}-docker.pkg.dev/{PROJECT_ID}/{APP_NAME}-repo/{APP_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaffa9d7-95e1-46cf-85ed-8407eb7a21fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gcloud run deploy {APP_NAME} --allow-unauthenticated --platform=managed --region=asia-southeast1 -q --set-env-vars=PROJECT_ID={PROJECT_ID},DATASTORE_ID={DATASTORE_ID} --image={LOCATION}-docker.pkg.dev/{PROJECT_ID}/{APP_NAME}-repo/{APP_NAME}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
